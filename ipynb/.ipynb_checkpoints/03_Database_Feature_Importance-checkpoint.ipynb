{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the 3 Database dataset \n",
    "# Create new dataframe with only the top 20 salient features found previouslous and try to find the top important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run __init__.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_1 = pd.read_pickle('./Datasets/database_1.p')\n",
    "db_2 = pd.read_pickle('./Datasets/database_2.p')\n",
    "db_3 = pd.read_pickle('./Datasets/database_3.p')\n",
    "# top 20 features found \n",
    "db_top_20 =  ['feat_257', 'feat_269', 'feat_308', 'feat_315', 'feat_336', 'feat_341', \n",
    "                   'feat_395', 'feat_504', 'feat_526', 'feat_639', 'feat_681', 'feat_701', \n",
    "                   'feat_724', 'feat_736', 'feat_769', 'feat_808', 'feat_829', 'feat_867',\n",
    "                   'feat_920', 'feat_956']\n",
    "\n",
    "#create X and y dataframes from samplesets \n",
    "db_y_1 = db_1['target']\n",
    "db_x_1 = db_1[db_top_20]\n",
    "db_y_2 = db_2['target']\n",
    "db_x_2 = db_2[db_top_20]\n",
    "db_y_3 = db_3['target']\n",
    "db_x_3 = db_3[db_top_20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find top 5 feats from sample datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skb_5_feats(x, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size=.2, \n",
    "                                                    random_state=42)\n",
    "    skb_list = []\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    skb = SelectKBest(k=5, score_func=f_regression)\n",
    "    skb.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    skb_feats = x.columns[skb.get_support()]\n",
    "    \n",
    "    skb_list.append(skb_feats)\n",
    "    \n",
    "    return skb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['feat_269' 'feat_341' 'feat_681' 'feat_701' 'feat_920']]\n",
      "[['feat_269' 'feat_341' 'feat_681' 'feat_701' 'feat_920']]\n",
      "[['feat_269' 'feat_341' 'feat_681' 'feat_701' 'feat_920']]\n"
     ]
    }
   ],
   "source": [
    "# find top 5 features from each sample set\n",
    "db_1 = skb_5_feats(db_x_1, db_y_1)\n",
    "db_2 = skb_5_feats(db_x_2, db_y_2)\n",
    "db_3 = skb_5_feats(db_x_3, db_y_3)\n",
    "\n",
    "print(np.sort(db_1))\n",
    "print(np.sort(db_2))\n",
    "print(np.sort(db_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKB of 3 samplesets show consistent top 5 features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 features of SKB from sample sets are not the same, try RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rfe_5_feats(x, y, estimator = DecisionTreeClassifier(max_depth=10)):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size=.2, \n",
    "                                                    random_state=42)\n",
    "    \n",
    "    rfe_list = []\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    rfe = RFE(estimator = estimator, n_features_to_select=5)\n",
    "    rfe.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    rfe_feats = x.columns[rfe.get_support()]\n",
    "    rfe_list.append(rfe_feats)\n",
    "    \n",
    "    return rfe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['feat_269' 'feat_639' 'feat_769' 'feat_808' 'feat_920']]\n",
      "[['feat_269' 'feat_724' 'feat_736' 'feat_769' 'feat_829']]\n",
      "[['feat_269' 'feat_736' 'feat_769' 'feat_808' 'feat_829']]\n"
     ]
    }
   ],
   "source": [
    "db_1_rfe = rfe_5_feats(db_x_1, db_y_1)\n",
    "db_2_rfe = rfe_5_feats(db_x_2, db_y_2)\n",
    "db_3_rfe = rfe_5_feats(db_x_3, db_y_3)\n",
    "\n",
    "print(np.sort(db_1_rfe))\n",
    "print(np.sort(db_2_rfe))\n",
    "print(np.sort(db_3_rfe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top features from RFE overlap with some of SKB features but are not the exact same 5 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to find important features with Randomforest pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_importance(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)\n",
    "    \n",
    "    \n",
    "    rf_pipe = Pipeline([('scaler',StandardScaler()),\n",
    "    ('clf',RandomForestClassifier(random_state=42))])\n",
    "    \n",
    "    rfparams = {\n",
    "    'clf__n_estimators':[10,50],\n",
    "    'clf__max_features':['auto','log2']}\n",
    "    \n",
    "    rfgs = GridSearchCV(rf_pipe, rfparams, cv=5, n_jobs=-1)\n",
    "    \n",
    "    rfgs.fit(X_train, y_train)\n",
    "    \n",
    "    important_features = rfgs.best_estimator_.named_steps['clf']\n",
    "    \n",
    "    return important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_1 = feature_importance(db_x_1, db_y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=50, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gini-importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat_269</th>\n",
       "      <td>0.063983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_681</th>\n",
       "      <td>0.059348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_920</th>\n",
       "      <td>0.056407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_808</th>\n",
       "      <td>0.055638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_395</th>\n",
       "      <td>0.054439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Gini-importance\n",
       "feat_269         0.063983\n",
       "feat_681         0.059348\n",
       "feat_920         0.056407\n",
       "feat_808         0.055638\n",
       "feat_395         0.054439"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_1 = feature_importance(db_x_1, db_y_1)\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(db_x_1.columns, db_1.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "\n",
    "importances.sort_values(['Gini-importance'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gini-importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat_269</th>\n",
       "      <td>0.061722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_808</th>\n",
       "      <td>0.058546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_920</th>\n",
       "      <td>0.057916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_681</th>\n",
       "      <td>0.056911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_724</th>\n",
       "      <td>0.054921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Gini-importance\n",
       "feat_269         0.061722\n",
       "feat_808         0.058546\n",
       "feat_920         0.057916\n",
       "feat_681         0.056911\n",
       "feat_724         0.054921"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_2 = feature_importance(db_x_2, db_y_2)\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(db_x_2.columns, db_2.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances_2 = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "\n",
    "importances_2.sort_values(['Gini-importance'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gini-importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat_269</th>\n",
       "      <td>0.061508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_920</th>\n",
       "      <td>0.060861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_681</th>\n",
       "      <td>0.060241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_308</th>\n",
       "      <td>0.055306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_701</th>\n",
       "      <td>0.055205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Gini-importance\n",
       "feat_269         0.061508\n",
       "feat_920         0.060861\n",
       "feat_681         0.060241\n",
       "feat_308         0.055306\n",
       "feat_701         0.055205"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_3 = feature_importance(db_x_3, db_y_3)\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(db_x_3.columns, db_3.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances_3 = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "\n",
    "importances_3.sort_values(['Gini-importance'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are some overlap of features with the other methods, results are still inconclusive of which 5 features are the most important, therefore, I'm keeping all 20 salient features in model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
