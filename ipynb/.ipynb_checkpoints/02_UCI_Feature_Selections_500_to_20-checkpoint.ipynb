{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selections: Iterative Method 500 to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run __init__.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv('./Datasets/madelon_train.labels', sep=' ', header=None)\n",
    "train = pd.read_csv('./Datasets/madelon_train.data', sep=' ', header=None)\n",
    "val = pd.read_csv('./Datasets/madelon_valid.data', sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target.columns = ['target']\n",
    "train = train.drop(train.columns[500], axis=1)\n",
    "\n",
    "train= pd.concat([train, target], 1)\n",
    "\n",
    "X = train.drop(['target'], axis=1)\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = train.sample(440)\n",
    "\n",
    "Uci_y_1 = sample1['target']\n",
    "Uci_X_1 = sample1.drop(['target'], axis=1)\n",
    "Uci_X_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use this function to find r2 of redundant features \n",
    "# dropping a feature and seeing if the other features can predict it\n",
    "def calculate_r_2_for_feature(data,feature):\n",
    "    new_data = data.drop(feature, axis=1)\n",
    "\n",
    "    X_train, \\\n",
    "    X_test,  \\\n",
    "    y_train, \\\n",
    "    y_test = train_test_split(\n",
    "        new_data,data[feature],test_size=0.25\n",
    "    )\n",
    "\n",
    "    regressor = KNeighborsRegressor()\n",
    "    regressor.fit(X_train,y_train)\n",
    "\n",
    "    score = regressor.score(X_test,y_test)\n",
    "    return score\n",
    "\n",
    "#use this function to take the mean of the scores after 100 runs\n",
    "def mean_r2_for_feature(data, feature):\n",
    "    scores = []\n",
    "    for _ in range(10):\n",
    "        scores.append(calculate_r_2_for_feature(data, feature))\n",
    "        \n",
    "    scores = np.array(scores)\n",
    "    return scores.mean()\n",
    "\n",
    "# use this function to get the mean of scores of multiple columns \n",
    "def mean_column_range_Knn(data):\n",
    "    r2_knn = []\n",
    "    for i in tqdm(range(0,500)):\n",
    "        if mean_r2_for_feature(data, i) > 0:\n",
    "            r2_knn.append(i)\n",
    "    return r2_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:54<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "r2_knn = mean_column_range_Knn(Uci_X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28,\n",
       " 48,\n",
       " 64,\n",
       " 105,\n",
       " 128,\n",
       " 153,\n",
       " 241,\n",
       " 281,\n",
       " 318,\n",
       " 336,\n",
       " 338,\n",
       " 378,\n",
       " 433,\n",
       " 442,\n",
       " 451,\n",
       " 453,\n",
       " 455,\n",
       " 472,\n",
       " 475,\n",
       " 493]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use this function to find r2 of redundant features \n",
    "# dropping a feature and seeing if the other features can predict it\n",
    "def calculate_r_2_for_feature_tree(data,feature):\n",
    "    new_data = data.drop(feature, axis=1)\n",
    "\n",
    "    X_train, \\\n",
    "    X_test,  \\\n",
    "    y_train, \\\n",
    "    y_test = train_test_split(\n",
    "        new_data,data[feature],test_size=0.25\n",
    "    )\n",
    "\n",
    "    regressor = DecisionTreeRegressor()\n",
    "    regressor.fit(X_train,y_train)\n",
    "\n",
    "    score = regressor.score(X_test,y_test)\n",
    "    return score\n",
    "\n",
    "#use this function to take the mean of the scores after 100 runs\n",
    "def mean_r2_for_feature_tree(data, feature):\n",
    "    scores = []\n",
    "    for _ in range(5):\n",
    "        scores.append(calculate_r_2_for_feature_tree(data, feature))\n",
    "        \n",
    "    scores = np.array(scores)\n",
    "    return scores.mean()\n",
    "\n",
    "# use this function to get the mean of scores of multiple columns \n",
    "def mean_column_range_tree(data):\n",
    "    r2_tree= []\n",
    "    for i in tqdm(range(0,500)):\n",
    "        if mean_r2_for_feature_tree(data, i) > 0:\n",
    "            r2_tree.append(i)\n",
    "    return r2_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:06<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "r2_tree = mean_column_range_tree(Uci_X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28,\n",
       " 48,\n",
       " 64,\n",
       " 105,\n",
       " 128,\n",
       " 153,\n",
       " 241,\n",
       " 281,\n",
       " 318,\n",
       " 336,\n",
       " 338,\n",
       " 378,\n",
       " 433,\n",
       " 442,\n",
       " 451,\n",
       " 453,\n",
       " 455,\n",
       " 472,\n",
       " 475,\n",
       " 493]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(r2_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both top R2 scores from Knn and DecisionTree show the same columns this indicates that these are the top 20 features that are important. So I will keep columns 28, 48, 64, 105, 128, 153, 241, 281, 318, 336, 338, 378, 433, 442, 451, 453, 455, 472, 475, 493)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_20 = [28, 48, 64, 105, 128, 153, 241, 281, 318, 336, 338, 378, 433,\n",
    "          442, 451, 453, 455, 472, 475, 493]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skb_top_feats(x, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size=.2, \n",
    "                                                    random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    skb_list = []\n",
    "    skb = SelectKBest(k=20, score_func=f_regression)\n",
    "    skb.fit(X_train, y_train)\n",
    "    \n",
    "    skb_feats = np.where(skb.get_support())[0]\n",
    "    \n",
    "    skb_list.append(skb_feats)\n",
    "    \n",
    "    return skb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uci_skb_feats = skb_top_feats(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 48,  64, 105, 128, 137, 149, 199, 204, 241, 282, 329, 336, 338,\n",
       "        378, 424, 442, 453, 472, 475, 493])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_skb_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uci_skb_feats = [48, 64, 105, 128, 137, 149, 199, 204, 241, 282, 329, 336, 338, 378,\n",
    "        424, 442, 453, 472, 475, 493]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "64\n",
      "105\n",
      "128\n",
      "241\n",
      "336\n",
      "338\n",
      "378\n",
      "442\n",
      "453\n",
      "472\n",
      "475\n",
      "493\n"
     ]
    }
   ],
   "source": [
    "for i in uci_skb_feats:\n",
    "    if i in top_20:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_df = X.corr().abs()\n",
    "corr_df = corr_df > .5\n",
    "corr_df = corr_df[corr_df].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28,\n",
       " 48,\n",
       " 64,\n",
       " 105,\n",
       " 128,\n",
       " 153,\n",
       " 241,\n",
       " 281,\n",
       " 318,\n",
       " 336,\n",
       " 338,\n",
       " 378,\n",
       " 433,\n",
       " 442,\n",
       " 451,\n",
       " 453,\n",
       " 455,\n",
       " 472,\n",
       " 475,\n",
       " 493]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_corr = list(corr_df[corr_df >1].index)\n",
    "top_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[28, 48, 64, 105, 128, 153, 241, 281, 318, 336, 338, 378, 433,\n",
    "          442, 451, 453, 455, 472, 475, 493]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert top_corr == top_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though SelectKbest did not give the same 20 columns as R2 method, 13 of SelectKbest columns were in R2 method. The correlation matrix method also gave the same top 20 columns as the R2 method.  Therefore, these will be the 20 important columns that would be used to run the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_pickle('./Datasets/train_clean.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
